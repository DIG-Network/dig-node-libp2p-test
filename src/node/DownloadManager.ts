/**
 * Download Manager for DIG Network
 * 
 * Features:
 * - Interruptible and resumable downloads
 * - Parallel byte-range downloads from multiple peers
 * - Temporary file management in ~/.dig folder
 * - Download progress tracking
 * - Automatic promotion to .dig file when complete
 * - Download recovery and retry logic
 */

import { createHash } from 'crypto'
import { readFile, writeFile, access, mkdir, unlink, stat } from 'fs/promises'
import { createReadStream, createWriteStream } from 'fs'
import { join, dirname } from 'path'
import { Logger } from './logger.js'

export class DownloadManager {
  private logger = new Logger('DownloadManager')
  private activeDownloads = new Map<string, DownloadSession>()
  private downloadDir: string
  private digNode: any // Reference to DIGNode for LibP2P access

  constructor(digPath: string, digNode?: any) {
    this.downloadDir = join(digPath, '.downloads')
    this.digNode = digNode
    this.ensureDownloadDirectory()
  }

  // Set DIGNode reference for LibP2P access
  setDIGNode(digNode: any): void {
    this.digNode = digNode
  }

  // Ensure download directory exists
  private async ensureDownloadDirectory(): Promise<void> {
    try {
      await access(this.downloadDir)
    } catch {
      try {
        await mkdir(this.downloadDir, { recursive: true })
        this.logger.info(`üìÅ Created download directory: ${this.downloadDir}`)
      } catch (error) {
        this.logger.error('Failed to create download directory:', error)
      }
    }
  }

  // Start a new download session (resumable)
  async startDownload(storeId: string, totalSize: number, sources: DownloadSource[]): Promise<DownloadSession> {
    try {
      // Check if download already exists
      let session = this.activeDownloads.get(storeId)
      
      if (session) {
        this.logger.info(`üì• Resuming existing download: ${storeId}`)
        return session
      }

      // Create new download session
      session = {
        storeId,
        totalSize,
        downloadedBytes: 0,
        sources,
        chunks: new Map(),
        tempFilePath: join(this.downloadDir, `${storeId}.temp`),
        metadataPath: join(this.downloadDir, `${storeId}.meta`),
        status: 'initializing',
        startTime: Date.now(),
        lastActivity: Date.now(),
        chunkSize: 256 * 1024, // 256KB chunks
        maxConcurrentChunks: 4,
        activeChunks: new Set(),
        completedChunks: new Set(),
        failedChunks: new Set()
      }

      // Try to resume from existing partial download
      await this.loadDownloadMetadata(session)

      this.activeDownloads.set(storeId, session)
      this.logger.info(`üì• Started download session: ${storeId} (${totalSize} bytes, ${sources.length} sources)`)

      return session

    } catch (error) {
      this.logger.error(`Failed to start download for ${storeId}:`, error)
      throw error
    }
  }

  // Download with parallel byte-range support
  async downloadWithParallelRanges(session: DownloadSession): Promise<boolean> {
    try {
      session.status = 'downloading'
      session.lastActivity = Date.now()

      this.logger.info(`üì• Starting parallel download: ${session.storeId} (${session.totalSize} bytes from ${session.sources.length} sources)`)

      // Calculate chunks
      const totalChunks = Math.ceil(session.totalSize / session.chunkSize)
      const downloadTasks: Promise<boolean>[] = []

      // Create download tasks for missing chunks
      for (let chunkIndex = 0; chunkIndex < totalChunks; chunkIndex++) {
        if (session.completedChunks.has(chunkIndex)) {
          continue // Skip already completed chunks
        }

        if (session.activeChunks.size >= session.maxConcurrentChunks) {
          break // Limit concurrent downloads
        }

        const rangeStart = chunkIndex * session.chunkSize
        const rangeEnd = Math.min(rangeStart + session.chunkSize - 1, session.totalSize - 1)
        const sourceIndex = chunkIndex % session.sources.length
        const source = session.sources[sourceIndex]

        session.activeChunks.add(chunkIndex)
        
        const downloadTask = this.downloadChunk(session, chunkIndex, rangeStart, rangeEnd, source)
        downloadTasks.push(downloadTask)
      }

      // Execute parallel downloads
      const results = await Promise.allSettled(downloadTasks)
      
      // Process results
      let successCount = 0
      for (const result of results) {
        if (result.status === 'fulfilled' && result.value) {
          successCount++
        }
      }

      this.logger.info(`üìä Parallel download batch: ${successCount}/${results.length} chunks successful`)

      // Check if download is complete
      if (session.completedChunks.size === totalChunks) {
        return await this.finalizeDownload(session)
      }

      // Save progress
      await this.saveDownloadMetadata(session)
      
      // Continue with remaining chunks if any failed
      if (session.failedChunks.size > 0) {
        this.logger.info(`üîÑ Retrying ${session.failedChunks.size} failed chunks...`)
        // Recursive call to retry failed chunks
        return await this.downloadWithParallelRanges(session)
      }

      return false // Not complete yet

    } catch (error) {
      this.logger.error(`Parallel download failed for ${session.storeId}:`, error)
      session.status = 'failed'
      return false
    }
  }

  // Download a single chunk
  private async downloadChunk(
    session: DownloadSession, 
    chunkIndex: number, 
    rangeStart: number, 
    rangeEnd: number, 
    source: DownloadSource
  ): Promise<boolean> {
    try {
      this.logger.debug(`üì¶ Downloading chunk ${chunkIndex}: ${rangeStart}-${rangeEnd} from ${source.peerId}`)

      // Download chunk data based on source type
      let chunkData: Buffer | null = null

      switch (source.type) {
        case 'libp2p':
          chunkData = await this.downloadChunkFromLibP2P(session.storeId, rangeStart, rangeEnd, source)
          break
        case 'turn':
          chunkData = await this.downloadChunkFromTurn(session.storeId, rangeStart, rangeEnd, source)
          break
        case 'bootstrap':
          chunkData = await this.downloadChunkFromBootstrap(session.storeId, rangeStart, rangeEnd, source)
          break
        default:
          throw new Error(`Unknown source type: ${source.type}`)
      }

      if (chunkData && chunkData.length > 0) {
        // Store chunk data
        session.chunks.set(chunkIndex, chunkData)
        session.completedChunks.add(chunkIndex)
        session.downloadedBytes += chunkData.length
        session.lastActivity = Date.now()

        this.logger.debug(`‚úÖ Chunk ${chunkIndex} downloaded: ${chunkData.length} bytes from ${source.peerId}`)
        return true
      } else {
        throw new Error('No data received')
      }

    } catch (error) {
      this.logger.debug(`‚ùå Chunk ${chunkIndex} download failed from ${source.peerId}:`, error)
      session.failedChunks.add(chunkIndex)
      return false
    } finally {
      session.activeChunks.delete(chunkIndex)
    }
  }

  // Download chunk from LibP2P peer (FULL PRODUCTION IMPLEMENTATION)
  private async downloadChunkFromLibP2P(storeId: string, rangeStart: number, rangeEnd: number, source: DownloadSource): Promise<Buffer | null> {
    try {
      if (!this.digNode) {
        throw new Error('DIGNode reference not set')
      }

      this.logger.debug(`üîó Downloading chunk via LibP2P: ${source.peerId} (${rangeStart}-${rangeEnd})`)

      // Get peer connection from DIGNode
      const peer = this.digNode.node.getPeers().find((p: any) => p.toString() === source.peerId)
      if (!peer) {
        throw new Error(`Peer ${source.peerId} not connected`)
      }

      // Send GET_FILE_RANGE request via DIG protocol
      const stream = await this.digNode.node.dialProtocol(peer, '/dig/1.0.0')
      
      const rangeRequest = {
        type: 'GET_FILE_RANGE',
        storeId,
        filePath: `${storeId}.dig`,
        rangeStart,
        rangeEnd,
        chunkId: `libp2p_chunk_${Math.floor(rangeStart / 262144)}_${Date.now()}`
      }

      // Send request using pipe
      const { pipe } = await import('it-pipe')
      const { fromString: uint8ArrayFromString, toString: uint8ArrayToString } = await import('uint8arrays')

      await pipe(async function* () {
        yield uint8ArrayFromString(JSON.stringify(rangeRequest))
      }, stream.sink)

      // Receive chunk data
      const chunks: Uint8Array[] = []
      await pipe(stream.source, async function (source: any) {
        for await (const chunk of source) {
          chunks.push(chunk instanceof Uint8Array ? chunk : new Uint8Array(chunk.subarray()))
        }
      })

      if (chunks.length === 0) {
        throw new Error('No response received')
      }

      // Parse response header
      const responseText = uint8ArrayToString(chunks[0])
      const lines = responseText.split('\n')
      const headerLine = lines[0]
      
      let response
      try {
        response = JSON.parse(headerLine)
      } catch {
        throw new Error('Invalid response format')
      }

      if (!response.success) {
        throw new Error(response.error || 'Chunk request failed')
      }

      // Extract chunk data (skip header)
      const headerLength = Buffer.from(headerLine + '\n').length
      const chunkData = Buffer.concat(chunks.map(c => Buffer.from(c))).subarray(headerLength)

      // Validate chunk size
      const expectedSize = rangeEnd - rangeStart + 1
      if (chunkData.length !== expectedSize) {
        this.logger.warn(`‚ö†Ô∏è LibP2P chunk size mismatch: expected ${expectedSize}, got ${chunkData.length}`)
      }

      this.logger.debug(`‚úÖ LibP2P chunk downloaded: ${chunkData.length} bytes from ${source.peerId}`)
      return chunkData

    } catch (error) {
      this.logger.debug(`LibP2P chunk download failed from ${source.peerId}:`, error)
      return null
    }
  }

  // Download chunk from TURN server (simplified)
  private async downloadChunkFromTurn(storeId: string, rangeStart: number, rangeEnd: number, source: DownloadSource): Promise<Buffer | null> {
    try {
      if (!source.url) {
        throw new Error('TURN server URL not provided')
      }

      this.logger.debug(`üì° TURN chunk download: ${source.peerId} (${rangeStart}-${rangeEnd})`)

      // Use unified TURN coordination instead of duplicate logic
      const turnCoordination = this.digNode.turnCoordination
      if (turnCoordination) {
        return await turnCoordination.requestChunk(storeId, rangeStart, rangeEnd, source.peerId)
      }

      throw new Error('TURN coordination not available')

    } catch (error) {
      this.logger.debug(`TURN chunk download failed:`, error)
      return null
    }
  }

  // Removed downloadChunkFromTurnDirect - functionality moved to UnifiedTurnCoordination

  // Download chunk from bootstrap server
  private async downloadChunkFromBootstrap(storeId: string, rangeStart: number, rangeEnd: number, source: DownloadSource): Promise<Buffer | null> {
    try {
      this.logger.debug(`‚òÅÔ∏è Downloading chunk via bootstrap server: ${rangeStart}-${rangeEnd}`)

      // Try direct HTTP TURN first (more reliable)
      const directResponse = await fetch(`${source.url}/bootstrap-turn-direct`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          storeId,
          fromPeerId: source.peerId,
          toPeerId: 'requesting-peer'
        }),
        signal: AbortSignal.timeout(15000)
      })

      if (directResponse.ok) {
        const directData = await directResponse.json()
        if (directData.success && directData.sourceAddresses) {
          this.logger.debug(`üì° Bootstrap provided addresses for direct connection`)
          // In full implementation, would use provided addresses
          // For now, fall back to regular bootstrap TURN
        }
      }

      // Fallback to WebSocket-based bootstrap TURN
      const response = await fetch(`${source.url}/bootstrap-turn-relay`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          storeId,
          fromPeerId: source.peerId,
          toPeerId: 'requesting-peer',
          rangeStart,
          rangeEnd,
          chunkId: `bootstrap_chunk_${Math.floor(rangeStart / 262144)}_${Date.now()}`
        }),
        signal: AbortSignal.timeout(30000)
      })

      if (response.ok) {
        const arrayBuffer = await response.arrayBuffer()
        const chunkData = Buffer.from(arrayBuffer)
        
        // Validate chunk data (detect 185-byte JSON errors)
        if (chunkData.length < 1000 && chunkData.toString().includes('{')) {
          this.logger.warn(`‚ö†Ô∏è Bootstrap returned JSON error instead of chunk data: ${chunkData.toString().substring(0, 100)}`)
          return null
        }
        
        // Validate chunk size
        const expectedSize = rangeEnd - rangeStart + 1
        if (chunkData.length !== expectedSize) {
          this.logger.warn(`‚ö†Ô∏è Bootstrap chunk size mismatch: expected ${expectedSize}, got ${chunkData.length}`)
        }

        this.logger.debug(`‚úÖ Bootstrap chunk downloaded: ${chunkData.length} bytes`)
        return chunkData
      }

      return null

    } catch (error) {
      this.logger.debug(`Bootstrap chunk download failed:`, error)
      return null
    }
  }

  // Finalize download by assembling chunks and promoting to .dig file
  private async finalizeDownload(session: DownloadSession): Promise<boolean> {
    try {
      this.logger.info(`üîß Finalizing download: ${session.storeId}`)

      // Assemble all chunks in order
      const assembledData = Buffer.alloc(session.totalSize)
      let offset = 0

      const sortedChunks = Array.from(session.chunks.entries()).sort((a, b) => a[0] - b[0])
      
      for (const [chunkIndex, chunkData] of sortedChunks) {
        chunkData.copy(assembledData, offset)
        offset += chunkData.length
      }

      // Verify data integrity
      const actualSize = assembledData.length
      if (actualSize !== session.totalSize) {
        throw new Error(`Size mismatch: expected ${session.totalSize}, got ${actualSize}`)
      }

      // Calculate checksum for verification
      const checksum = createHash('sha256').update(assembledData).digest('hex')
      this.logger.info(`üîê Download checksum: ${checksum}`)

      // Write to final .dig file location
      const finalPath = join(dirname(session.tempFilePath), '..', `${session.storeId}.dig`)
      await writeFile(finalPath, assembledData)

      // Clean up temporary files
      await this.cleanupDownload(session)

      session.status = 'completed'
      this.activeDownloads.delete(session.storeId)

      this.logger.info(`‚úÖ Download completed: ${session.storeId} (${actualSize} bytes) ‚Üí ${finalPath}`)
      return true

    } catch (error) {
      this.logger.error(`Failed to finalize download for ${session.storeId}:`, error)
      session.status = 'failed'
      return false
    }
  }

  // Save download metadata for resumability
  private async saveDownloadMetadata(session: DownloadSession): Promise<void> {
    try {
      const metadata = {
        storeId: session.storeId,
        totalSize: session.totalSize,
        downloadedBytes: session.downloadedBytes,
        completedChunks: Array.from(session.completedChunks),
        failedChunks: Array.from(session.failedChunks),
        sources: session.sources,
        lastActivity: session.lastActivity,
        chunkSize: session.chunkSize
      }

      await writeFile(session.metadataPath, JSON.stringify(metadata, null, 2))
      this.logger.debug(`üíæ Saved download metadata: ${session.storeId}`)

    } catch (error) {
      this.logger.debug(`Failed to save metadata for ${session.storeId}:`, error)
    }
  }

  // Load download metadata for resuming
  private async loadDownloadMetadata(session: DownloadSession): Promise<void> {
    try {
      await access(session.metadataPath)
      const metadataContent = await readFile(session.metadataPath, 'utf-8')
      const metadata = JSON.parse(metadataContent)

      // Restore session state
      session.downloadedBytes = metadata.downloadedBytes || 0
      session.completedChunks = new Set(metadata.completedChunks || [])
      session.failedChunks = new Set(metadata.failedChunks || [])
      session.lastActivity = metadata.lastActivity || Date.now()

      this.logger.info(`üì• Resumed download: ${session.storeId} (${session.downloadedBytes}/${session.totalSize} bytes, ${session.completedChunks.size} chunks completed)`)

    } catch (error) {
      this.logger.debug(`No existing download metadata for ${session.storeId}`)
    }
  }

  // Clean up temporary files
  private async cleanupDownload(session: DownloadSession): Promise<void> {
    try {
      // Remove temporary files
      await unlink(session.tempFilePath).catch(() => {})
      await unlink(session.metadataPath).catch(() => {})
      
      this.logger.debug(`üßπ Cleaned up temporary files for ${session.storeId}`)

    } catch (error) {
      this.logger.debug(`Cleanup failed for ${session.storeId}:`, error)
    }
  }

  // Cancel a download
  async cancelDownload(storeId: string): Promise<void> {
    const session = this.activeDownloads.get(storeId)
    if (session) {
      session.status = 'cancelled'
      await this.cleanupDownload(session)
      this.activeDownloads.delete(storeId)
      this.logger.info(`üö´ Cancelled download: ${storeId}`)
    }
  }

  // Get download progress
  getDownloadProgress(storeId: string): DownloadProgress | null {
    const session = this.activeDownloads.get(storeId)
    if (!session) return null

    const progressPercentage = (session.downloadedBytes / session.totalSize) * 100
    const elapsedTime = Date.now() - session.startTime
    const downloadSpeed = session.downloadedBytes / (elapsedTime / 1000) // bytes per second

    return {
      storeId: session.storeId,
      totalSize: session.totalSize,
      downloadedBytes: session.downloadedBytes,
      progressPercentage,
      completedChunks: session.completedChunks.size,
      totalChunks: Math.ceil(session.totalSize / session.chunkSize),
      activeChunks: session.activeChunks.size,
      failedChunks: session.failedChunks.size,
      downloadSpeed,
      elapsedTime,
      status: session.status,
      sources: session.sources.length
    }
  }

  // List all active downloads
  getActiveDownloads(): DownloadProgress[] {
    return Array.from(this.activeDownloads.keys()).map(storeId => 
      this.getDownloadProgress(storeId)!
    ).filter(Boolean)
  }

  // Resume all incomplete downloads on startup (FULL PRODUCTION IMPLEMENTATION)
  async resumeIncompleteDownloads(): Promise<void> {
    try {
      const { readdir } = await import('fs/promises')
      const files = await readdir(this.downloadDir).catch(() => [])
      
      this.logger.info(`üîç Scanning for incomplete downloads in ${this.downloadDir}`)
      
      for (const file of files) {
        if (file.endsWith('.meta')) {
          const storeId = file.replace('.meta', '')
          try {
            const metadataPath = join(this.downloadDir, file)
            const metadata = JSON.parse(await readFile(metadataPath, 'utf-8'))
            
            this.logger.info(`üîÑ Found incomplete download: ${storeId} (${metadata.downloadedBytes}/${metadata.totalSize} bytes)`)
            
            // Resume the download session
            const session: DownloadSession = {
              storeId: metadata.storeId,
              totalSize: metadata.totalSize,
              downloadedBytes: metadata.downloadedBytes,
              sources: metadata.sources || [],
              chunks: new Map(),
              tempFilePath: join(this.downloadDir, `${storeId}.temp`),
              metadataPath,
              status: 'paused',
              startTime: Date.now(),
              lastActivity: metadata.lastActivity || Date.now(),
              chunkSize: metadata.chunkSize || 256 * 1024,
              maxConcurrentChunks: 4,
              activeChunks: new Set(),
              completedChunks: new Set(metadata.completedChunks || []),
              failedChunks: new Set(metadata.failedChunks || [])
            }

            this.activeDownloads.set(storeId, session)
            
            // Resume download automatically
            this.logger.info(`üîÑ Resuming download: ${storeId}`)
            this.downloadWithParallelRanges(session).catch(error => {
              this.logger.error(`Failed to resume download ${storeId}:`, error)
            })
            
          } catch (error) {
            this.logger.debug(`Failed to resume download ${storeId}:`, error)
          }
        }
      }

      this.logger.info(`üì• Resume scan complete: ${this.activeDownloads.size} downloads resumed`)

    } catch (error) {
      this.logger.debug('Failed to scan for incomplete downloads:', error)
    }
  }
}

// Download session state
export interface DownloadSession {
  storeId: string
  totalSize: number
  downloadedBytes: number
  sources: DownloadSource[]
  chunks: Map<number, Buffer>
  tempFilePath: string
  metadataPath: string
  status: 'initializing' | 'downloading' | 'completed' | 'failed' | 'cancelled' | 'paused'
  startTime: number
  lastActivity: number
  chunkSize: number
  maxConcurrentChunks: number
  activeChunks: Set<number>
  completedChunks: Set<number>
  failedChunks: Set<number>
}

// Download source definition
export interface DownloadSource {
  type: 'libp2p' | 'turn' | 'bootstrap'
  peerId: string
  url?: string
  cryptoIPv6?: string
  addresses?: string[]
  priority: number
  lastUsed?: number
  failures: number
}

// Download progress information
export interface DownloadProgress {
  storeId: string
  totalSize: number
  downloadedBytes: number
  progressPercentage: number
  completedChunks: number
  totalChunks: number
  activeChunks: number
  failedChunks: number
  downloadSpeed: number // bytes per second
  elapsedTime: number
  status: string
  sources: number
}
